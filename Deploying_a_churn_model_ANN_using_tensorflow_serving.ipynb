{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_nzvDWmsmx4"
      },
      "source": [
        "Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt-rUG-0smx-"
      },
      "source": [
        "Installing Tensorflow<br>\n",
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1beEy44smx_"
      },
      "source": [
        "Installing Keras<br>\n",
        "pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjUHzaKMsmyA"
      },
      "source": [
        "Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvv2H1qismyB"
      },
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G_vUnuSqsmyC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X34WKSVusmyD"
      },
      "source": [
        "Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T1NJa_C-smyE"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xgPh0eJEJ2Bo"
      },
      "outputs": [],
      "source": [
        "class_names = ['Exited', 'Not']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umfDdekrsmyF"
      },
      "source": [
        "Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeBp_RoGsmyG",
        "outputId": "f33f4241-8d17-4cd1-bba5-09ca79df685d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "\n",
        "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "\n",
        "X = np.array(columnTransformer.fit_transform(X), dtype = np.str)\n",
        "\n",
        "X = X[:, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WhIAWafsmyH"
      },
      "source": [
        "Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y4q9-OH1smyH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlpsgvDssmyI"
      },
      "source": [
        "Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hFwc-OtlsmyJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6w_jzZ1smyJ"
      },
      "source": [
        "Part 2 - Now let's make the ANN!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymmQ-n_XsmyK"
      },
      "source": [
        "Importing the Keras libraries and packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cAp1GktpsmyK"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3PCW8XqsmyL"
      },
      "source": [
        "Initialising the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oq0eOgX6smyL"
      },
      "outputs": [],
      "source": [
        "classifier = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16D2KWmTsmyL"
      },
      "source": [
        "Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pvORjLBksmyM"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQYWpOaTsmyM"
      },
      "source": [
        "Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3eg6xCg7smyN"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrtM0YP1smyN"
      },
      "source": [
        "Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fz3DEbv3smyN"
      },
      "outputs": [],
      "source": [
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiedNi_KsmyN"
      },
      "source": [
        "Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zonw5zT1smyO"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ILXyLlRsmyO"
      },
      "source": [
        "Fitting the ANN to the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w8rP7QhsmyO",
        "outputId": "a5d0f8cd-1a52-49fa-f4fe-2c5e8a3e9304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.4808 - accuracy: 0.7960\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4284 - accuracy: 0.7960\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4223 - accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.4188 - accuracy: 0.8207\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.4164 - accuracy: 0.8276\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4144 - accuracy: 0.8279\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.4124 - accuracy: 0.8319\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4118 - accuracy: 0.8329\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4104 - accuracy: 0.8334\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 0.4091 - accuracy: 0.8336\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4084 - accuracy: 0.8335\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4079 - accuracy: 0.8344\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8353\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4063 - accuracy: 0.8339\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4060 - accuracy: 0.8338\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4052 - accuracy: 0.8353\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4050 - accuracy: 0.8338\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4050 - accuracy: 0.8345\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4045 - accuracy: 0.8339\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4046 - accuracy: 0.8356\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4040 - accuracy: 0.8349\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4037 - accuracy: 0.8363\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4038 - accuracy: 0.8350\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4032 - accuracy: 0.8351\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4032 - accuracy: 0.8339\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4027 - accuracy: 0.8360\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8345\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4027 - accuracy: 0.8341\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8359\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4024 - accuracy: 0.8351\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4020 - accuracy: 0.8356\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4022 - accuracy: 0.8350\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4019 - accuracy: 0.8342\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4016 - accuracy: 0.8346\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8350\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4018 - accuracy: 0.8349\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8353\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4018 - accuracy: 0.8342\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4014 - accuracy: 0.8345\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8355\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8353\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4014 - accuracy: 0.8363\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8354\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4011 - accuracy: 0.8357\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4007 - accuracy: 0.8359\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4007 - accuracy: 0.8334\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8341\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4014 - accuracy: 0.8363\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4010 - accuracy: 0.8335\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4006 - accuracy: 0.8356\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4011 - accuracy: 0.8338\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4010 - accuracy: 0.8340\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4007 - accuracy: 0.8365\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8356\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4008 - accuracy: 0.8350\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8353\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8346\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8351\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8353\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8340\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8340\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.8350\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8340\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8349\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4009 - accuracy: 0.8344\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4005 - accuracy: 0.8347\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.8339\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4007 - accuracy: 0.8339\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8350\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8351\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8353\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8334\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8349\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8340\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4001 - accuracy: 0.8350\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 0.3996 - accuracy: 0.8339\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.4007 - accuracy: 0.8347\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4002 - accuracy: 0.8346\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4001 - accuracy: 0.8354\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8345\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8341\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8341\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8334\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3999 - accuracy: 0.8365\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8339\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8354\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8349\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8357\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8332\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8349\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3992 - accuracy: 0.8350\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8336\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8363\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3999 - accuracy: 0.8340\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8353\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8335\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8354\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8347\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4000 - accuracy: 0.8359\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8334\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f6297ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CFR9EJusmyP"
      },
      "source": [
        "Part 3 - Making predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abl7qE7zsmyP"
      },
      "source": [
        "Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bod-xwv-smyP"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmpDPRGVsmyQ",
        "outputId": "25d382a5-8d04-4366-ceba-bed16714d486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 6)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM9YDWtismyQ"
      },
      "source": [
        "Predicting a single new observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTUdrT62smyQ"
      },
      "source": [
        "\n",
        "Predict if the customer with the following informations will leave the bank:<br>\n",
        "Geography: France<br>\n",
        "Credit Score: 600<br>\n",
        "Gender: Male<br>\n",
        "Age: 40<br>\n",
        "Tenure: 3<br>\n",
        "Balance: 60000<br>\n",
        "Number of Products: 2<br>\n",
        "Has Credit Card: Yes<br>\n",
        "Is Active Member: Yes<br>\n",
        "timated Salary: 50000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GpBHjA6smyR",
        "outputId": "a24c9390-510b-4e4e-ae00-5b735c7adac9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
        "new_prediction = (new_prediction > 0.5)\n",
        "new_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAnZWIQKsmyR"
      },
      "source": [
        "Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezMIrCb6smyR",
        "outputId": "74711c53-2729-4163-e8d8-9cadb9ac357a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1538,   57],\n",
              "       [ 265,  140]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "f7mwnwimsmyS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "\n",
        "# Let's obtain a temporary storage directory\n",
        "MODEL_DIR = tempfile.gettempdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ye6C54PfsmyT",
        "outputId": "9360bf73-08d8-4737-e798-aa1afa7b1e09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "MODEL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "x6OgPVwhsmyT"
      },
      "outputs": [],
      "source": [
        "# Let's specify the model version\n",
        "version = 11 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va440u-zsmyU",
        "outputId": "a430fe3c-3019-4847-b3ec-416b7719368c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export_path = /tmp/11\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's join the temp model directory with our chosen version number \n",
        "# The expected result will be = '\\tmp\\version number'\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N9K2URGsmyU",
        "outputId": "e1dcbdf8-ac47-443c-a467-386b31a465d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/11/assets\n"
          ]
        }
      ],
      "source": [
        "tf.keras.models.save_model(\n",
        "    classifier,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XinaEP1lsmyU",
        "outputId": "45d8eb8f-687b-4b3f-a705-44cdd6626a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 104\n",
            "drwxr-xr-x 2 root root  4096 Apr 13 01:00 assets\n",
            "-rw-r--r-- 1 root root  8601 Apr 13 01:00 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 85001 Apr 13 01:00 saved_model.pb\n",
            "drwxr-xr-x 2 root root  4096 Apr 13 01:00 variables\n"
          ]
        }
      ],
      "source": [
        "!ls -l {export_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifOaCS5asmyV",
        "outputId": "92362e86-b25a-4083-fd2f-77254239cd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 11)\n",
            "        name: serving_default_dense_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_2'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 11), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 11), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 11), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 11), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 11), dtype=tf.float32, name='dense_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 11), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 11), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 11), dtype=tf.float32, name='dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 11), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt95qnjUsmyV"
      },
      "source": [
        "# Serve the model using tensorflow serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr53oxLtsmyV"
      },
      "source": [
        "# Let's add tensorflow-model-server package to our list of packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-GoqCZlsmyV",
        "outputId": "94c23fda-6215-484f-8d97-80f1735439fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0   136k      0 --:--:-- --:--:-- --:--:--  136k\n",
            "OK\n",
            "Hit:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "42 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg7lBfU7smyW"
      },
      "source": [
        "# Let's install tensorflow model server:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yE6a5Xy1smyW"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoAqUo6csmyW",
        "outputId": "9624897c-8dc9-41b9-b017-a14c34489268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ]
        }
      ],
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8502 \\\n",
        "  --model_name=churn_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wk4vJGUsmyX"
      },
      "source": [
        "# Let's start making requests in TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XSdQdC4FsmyX"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hBAZyFefsmyX"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY9qj2q5vUvW",
        "outputId": "54a3d994-0dc9-4f2a-859c-bdc8a79a7498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: {\"signature_name\": \"serving_default\", \"instances\": ... 87704583, 0.9687383975403476, -0.4247867388302741]]}\n"
          ]
        }
      ],
      "source": [
        "# Let's create a JSON object and make 3 inference requests\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": X_test[0:3].tolist()})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run it on your local machine"
      ],
      "metadata": {
        "id": "k9JS9Y-Za_J6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8502/v11/models/churn_model:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "\n",
        "for i in range(0,3):\n",
        "  show(i, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
        "    class_names[np.argmax(predictions[i])], np.argmax(predictions[i]), class_names[y_pred[i]], y_pred[i])) '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9PRuBOaHPwhA",
        "outputId": "48e0af7a-06d0-42b4-a272-81414f5cf95c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' headers = {\"content-type\": \"application/json\"}\\njson_response = requests.post(\\'http://localhost:8502/v11/models/churn_model:predict\\', data=data, headers=headers)\\npredictions = json.loads(json_response.text)[\\'predictions\\']\\n\\nfor i in range(0,3):\\n  show(i, \\'The model thought this was a {} (class {}), and it was actually a {} (class {})\\'.format(\\n    class_names[np.argmax(predictions[i])], np.argmax(predictions[i]), class_names[y_pred[i]], y_pred[i])) '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ykjUlusraync"
      },
      "execution_count": 31,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Deploying a churn model ANN using tensorflow serving.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}